操作系统60分

## 第一章 概述

（1）理解：操作系统的概念、设计目标、功能及特征，操作系统运行硬件基础，操作系统接口分类及组成，操作系统内核用典型数据结构；
（2）掌握：系统调用实现机制，操作系统启动引导过程。

（1）理解：批处理、分时和实时系统的概念，操作系统结构设计及演化，操作系统发展趋势。

#### 操作系统的概念

###### 操作系统的定义

操作系统是最基本的系统软件，是一组有效管理和控制计算机硬件和软件资源、合理地对各类作业进行调度以组织和控制系统工作流程，并方便用户使用计算机的程序的集合。

##### 操作系统的设计目标

- 方便性
  
  - 提供用户接口，使计算机系统更方便使用

- 有效性
  
  - 通过有效管理和分配软、硬件资源及合理组织计算机工作流程来改善资源利用率、提高系统吞吐量

- 可扩充性
  
  - 适应计算机硬件和体系结构的迅猛发展及其所对应的更高的功能和性能要求

- 开放性
  
  - 适应不同厂家与不同类型的计算机及其设备的网络化集成和协同工作，实现应用程序可移植性和互操作性

##### 操作系统的作用

用户与计算机硬件系统之间的接口

- 命令方式

- 系统调用方式 

计算机系统资源的管理者

- 管理对象：处理器、存储器、外围设备以及信息

- 管理内容：资源的分配、回收和访问操作，记录资源的当前状态、相应管理策略

用作扩充机器（或虚拟机）

#### 计算机体系结构及操作系统硬件基础

![](C:\Users\17131\AppData\Roaming\marktext\images\2022-09-27-21-52-11-image.png)![](C:\Users\17131\AppData\Roaming\marktext\images\2022-09-27-21-52-17-image.png)

操作系统运行硬件基础

#### 操作系统用户接口及系统调用实现

操作系统接口分类及组成

系统调用实现机制

- 系统调用通常通过软中断机制首先进入到系统核心空间

- 用户程序只在用户态下运行，如果需要访问系统核心功能，便须通过系统调用接口来进行访问

- 一般来说，操作系统的命令接口与图形化用户接口往往可以实现同样的操作，但后者更为直观和更方便使用

操作系统内核用典型数据结构

#### 操作系统启动模块及自装入机制

操作系统启动引导过程。

#### 操作系统发展

##### 手工操作阶段

程序的装入，运行，结果的输出都需要人为的干预
缺点：资源利用率低、CPU利用不充分

##### 批处理阶段

为了解决人机矛盾以及CPU和I/O设备之间速度不匹配的矛盾

###### 单道批处理系统

内存中始终保存一道作业，作业成批进行
特点：
    自动性：一批作业自动执行不需要人工干预
    顺序性：各道作业以此执行
    单道性：仅有一道程序执行

优点：缓解了一定程度的人机速度矛盾，资源利用率有所提升。
缺点：高速CPU等待IO设备完成，内存中仅能有一道程序运行，该程序运行结束才能调入下一道程序

###### 多道批处理系统

允许多个程序在CPU中交替运行，程序共享各种硬件和软件资源
特点：
    多道：计算机中同时存放多道相互独立的程序
    宏观上并行：多道程序都会开始运行，但都没有运行完毕
    微观上串行：多道程序轮流占有CPU，交替执行
优点：资源利用率高，多道程序并发执行，共享计算机资源，CPU和其他资源更能保持“忙碌”状态，系统吞吐量增大
缺点：设计复杂，要考虑各种资源调度问题，响应时间过长，没有人机交互功能

##### 分时操作系统

将处理器运行时间划分为时间片，将时间片分配给不同作业/用户从而占用处理机

特点：
    同时性：允许多个终端用户使用同一台计算机
    交互性：方便进行人机对话，用户采用人机对话方式控制
    独立性：多个用户彼此之间独立的操作，互不干扰
    及时性：用户请求能在很短时间内获得响应

##### 实时操作系统

保证在规定时间内完成某项任务

特点：
    及时性：规定时间内完成规定任务
    可靠性：输出的结果正确，系统运行时确保稳定

##### 分布式计算机系统

##### 个人计算机操作系统

#### 操作系统的功能与特征

##### 处理机管理功能

##### 存储器管理功能

##### 设备管理功能

##### 文件管理功能

##### 操作系统的基本特征

- 并发性：两个或两个以上的进程在执行时间上有重叠，即一个进程的第一个操作在另一个进程的最后一个操作完成之前开始。
- 共享性：系统中的硬件和软件资源能为多个用户共同使用。
- 虚拟性：把物理上的一个单位的资源转换为逻辑上的多个单位的资源。
  - 虚拟处理器——多道程序设计技术，并发运行程序共享CPU
  - 虚拟设备、虚拟存储技术——具有请求调入和置换功能
  - 假脱机技术
- 异步性：并发执行的多道程序的完成次序的不确定性以及重复执行某道程序所需运行时间的不可预知性。

#### 操作系统结构设计

#### 

**1.3 什么是输入输出重定向？什么是管道联接？分别加以举例说明。**

> - 输入重定向是指不使用系统提供的标准输入设备，并进行重新指定
> 
> - ps -A|grep ssh不是输入输出重定向语句
> 
> - ls -l>file.txt和ls -l>>file.txt都表示输出重定向
> 
> - 利用管道连接和grep命令可对ls的结果进行筛选，从而仅保留指定模式的信息

**1.4 试阐述程序接口与用户交互接口（即命令接口和图形化接口）之间的关系？并给出你对系统调用实现机制及处理过程的完整理解与总结。**

**1.5 谈谈你对脱机 I/O 和联机 I/O 的认识与理解**

①脱机I/O方式是指程序和数据的I/O都是在外围机的控制下完成的；
②联机I/O方式是指在主机的直接控制下进行的I/O；
③就脱机I/O方式而言，主机负责把计算结果记录到输出磁带上，然后由外围计算机控制实现输出磁带上信息的打印输出；
④对于联机I/O方式来说，程序运行结果的输出和打印都是由中央处理机直接控制而完成的

**1.6 试从多个角度来阐述单道/多道批处理系统与分时系统及实时系统的区别。**

- 分时系统是指系统拥有一台主机和多个终端，而且支持多个用户同时以交互方式使用计算机系统

- 实时系统指系统能及时响应外部事件请求，并在规定时间内完成对相应事件的处理

- 多道批处理系统中，多道作业完成的先后次序与它们进入内存的顺序之间，并无严格的对应关系

## 第二章 进程管理

（1）理解：

多道程序设计技术，

进程状态变迁，进程控制，进程同步基本准则，进程同步软硬件解决方案，整型信号量、记录型信号量、管程，经典同步问题，进程通信机制

线程同步机制，程序、进程、线程的区别与联系，线程实现方式，

处理机调度类型与模型，处理机调度实现机理，调度算法与评价准则，死锁及处理方法；
（2）掌握：利用记录型信号量解决同步问题，处理机主要调度算法设计实现及应用。利用银行家算法给出避免死锁的资源分配方案，死锁检测算法及应用。

### 进程

> *多道程序设计技术：
> 
> 为了提高资源利用率和系统吞吐量，在内存中同时存放多道程序，且交替并发执行，共享CPU及其他资源
> 主要优点是提高CPU效率、利用率，增大吞吐量。

##### 概念

为了更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性
进程控制块（Process Control Block）：为了更好的描述进程的基本情况和运行状态，进而控制和管理进程，作为进程存在的唯一标志。

典型定义：

    进程是程序的一次执行过程
    进程是一次程序及其数据在处理机上顺序执行时所发生的活动
    进程是具有独立功能的程序在一个数据集合上运行的过程，是资源分配和调度的独立单位

特征：

    动态性：动态性是进程最基本特征，进程有着创建、活动、暂停、终止等过程，具有生命周期
    并发性：多个进程实体同时存在内存中，引入进程的目的就是为了程序与其他程序并发执行
    独立性：进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位，没有建立PCB的程序，都不能作为一个独立单位参与运行
    异步性：进程相互制约，进程以不可预知的速度向前推进，所以操作系统中一定要配置响应的进程同步机制
    结构性：每个进程都配置一个PCB对其进行描述

进程实体：

    程序段
    数据段
    进程控制 

#### 进程的状态和相互转换*

状态：
    运行态：进程在处理机上运行
    就绪态：进程已处于准备运行状态
    阻塞态：又称等待态，进程正在等待某个时间而暂停运行
    创建态：进程正在被创建，尚未进入就绪态
    结束态：进程正在从系统中消失（包括正常结束或者异常终止）

相互转换：
    就绪态一一>运行态：处于就绪态的进程获得处理机进入运行态
    运行态一一>就绪态：处于运行态的进程时间片用完后，让出处理机进入就绪态
    运行态一一>阻塞态：进程请求除处理机外的其他资源，此时运行态进入阻塞态（系统调用请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式）
    阻塞态一一>就绪态：进程等待其他资源的获得，如IO资源、或者中断结束

#### 挂起操作和进程状态的转换

##### 引入挂起操作的原因

- 终端用户的请求
  
  - 程序运行期间发现可疑问题暂停进程

- 父进程的请求
  
  - 考察、修改或协调紫禁城

- 操作系统的需要
  
  - 运行中资源使用情况的检查和记账

- 负荷调节的需要
  
  - 负荷调节和保证实时系统正常运行

### 进程控制*

#### 进程控制块

作为进程实体的一部分，记录了描述进程情况以及控制进程运行的全部信息的记录行数据结构，是进程存在的唯一标志

##### 进程控制块的作用

- 作为独立运行基本单位的标指

- 能实现间断性运行方式

- 提供进程管理所需要的信息

- 提供进程调度所需要的信息

- 实现与其他进程的同步与通信

##### 进程控制块中的信息

1）进程标识符

2）处理机状态

3）进程调度信息

4）进程控制信息

##### 进程控制块的组织方式

#### 进程的创建与终止

###### 引起创建进程的事件：

- 用户登录

- 作业调度

- 提供服务

- 应用请求

###### 创建：

1. 申请空白PCB

2. 为新进程分配其运行所需的资源

3. 初始化PCB

4. 将新进程插入到就绪进程队列

###### 引起终止进程的事件：

- 正常结束

- 异常结束
  
  - 越界错误、保护错
  
  - 特权指令错
  
  - 非法指令
  
  - 运行超时、等待超时
  
  - 算术运算错、I/O故障

- 外界干预
  
  - 操作员或操作系统干预
  
  - 父进程请求/终止

###### 终止：

1. 检索被终止进程PCB，读取进程状态

2. 若其正处于执行状态，立即终止执行并设置调度标志为真，以指示调度进新进程

3. 终止子孙进程

4. 资源归还

5. 移出被终止进程PCB，等待其他程序查询利用

#### 进程的阻塞与唤醒

###### 引起进程阻塞与唤醒的事件：

- 请求系统服务

- 启动某种操作（等待操作完成）

- 新数据尚未到达

- 无新工作可做

###### 阻塞过程（Block（）原语）

- 先立即停止执行，把进程控制块中的现行状态由“执行”改为阻塞，插入到对应的阻塞队列中

- 转调度程序进行重新调度，将处理机分配给另一就绪进程，并切换

###### 唤醒过程（Wakeup（）原语）

- 首先把被阻塞进程从等待该事件的阻塞进程队列中移出，将其PCB中的现行状态由阻塞改为就绪，再插入到对应的就绪队列中

#### 进程的挂起与激活

###### 挂起（suspend（）原语）

1. 检查被挂起进程现行状态并修改和插队

2. 复制PCB到指定域

3. 若被挂起进程正在执行则转向调度程序重新调度

###### 激活（active（）原语）

1. 检查进程线性状态并修改和插队

2. 若有新进程进入就绪队列且采用了抢占式调度策略，则检查和决定是否重新调度

### 进程同步

###### 概念

同步：直接制约关系，为了完成某种任务建立的多个进程，相互合作，所以要相互进行通信同步

主要任务：对多个相关进程在执行次序上进行协调，使并发执行的就绪进程之间能按照一定的规则共享系统资源，并能很好地相互合作，从而使程序的执行具有可再现性

###### 临界资源与临界区

一次只允许一个进程使用的资源（打印机、特殊变量，数据）

访问过程：

进入区：检查进程是否可以进入临界区
临界区：可以访问临界资源的代码
退出区：将正在访问临界区的标志清除
剩余区：代码中的其余部分

###### *进程同步基本准则：

- 空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区

- 忙则等待：已有进程进入临界区后，其他试图进入临界区的进程必须等待，保证对临界资源的互斥访问

- 有限等待：对于请求访问临界区的进程，在有限时间内进入临界区，以防“饥饿”

- 让权等待：进程不能进入临界区的时候，应当立即释放处理机，以免“忙等”

#### 进程的互斥

间接制约关系，当一个进程访问临界资源的时候，其他进程不能访问。

#### *进程同步软硬件解决方案

##### 问题描述

- 由两个进程$P_i 、P_j$，共享某临界资源R

- ```clike
  begin
      parbegin
          pi;
          pj;    
      parend;
  end
  ```

##### 软件解决方案

- ###### 设置访问编号（单标志法）
  
  - 检查 不上锁
  - 违背“空闲让进”原则

- ###### 设置访问标志（双标志先检查法）
  
  - 先“检查“后”上锁
  - 违反”忙则等待“原则

- ###### 设置欲访问标志（双标志后检查法）
  
  - 先“上锁”后”检查“
  - 解决了”忙则等待“的问题，违背了“空闲让进”和”有限等待“原则，因各进程都长期无法访问临界资源产生”饥饿现象

- ###### Peterson算法

```cpp
bool flag[2];  //表示进入临界区意愿的数组，初始值都是false
int turn 0;    //turn表示优先让哪个进程进入临界区
// P0进程：
flag[0] = true;
turn 1;
while (flag[1] && turn==1);
critical section;
flag[0]=false;
remainder section;
// P1进程：
flag[1] = true;  //表示自己想进入临界区
turn 0;      //可以优先让对方进入临界区
while (flag[0] && turn==0);//对方想进，且最后一次是自己“让梨”，那自己就循环等待
critical section;
flag[1] = false;//访问完临界区，表示自己已经不想访问临界区了
remainder section;
```

遵循了空闲让进、忙则等待、有限等待三个原则，违背了让权等待的原则

##### 硬件实现方法

- ###### 关中断
  
  - 简单高效
  - 只适用于单处理机，只适用于操作系统内核进程

- ###### TestAndSetLock指令
  
  - 实现简单，适用于多处理机环境
  - 不满足”让权等待“原则，暂时无法进入临界区的进程会占用CPU并循环执行TSL，导致”忙等“
  - ```clike
    boolean TS(boolean *lock){
        boolean old;
        old = *lock;
        *lock = TRUE;
        return old;
    }
    //互斥的循环进程结构
    do{
        ...
        while TS(&lock); // do skip
        critical section;
        lock = FALSE;
        remainder section;
    }while(TRUE);
    ```

- ###### Swap指令（XCHG）
  
  - 逻辑上同TSL
  - ```clike
    void swap(boolean *a, boolean *b){
        boolean temp;    
        temp = *a;
        *a = *b;
        *b = temp;
    }
    //互斥的循环进程结构
    do{
        key = TRUE;
        do{
            swap(&lock, &key);
        }while(key!=FALSE);
        critical section;
        lock = FALSE;
        remainder section;    
    }while(TRUE);
    ```

###### 局限性

- 能有效地实现进程互斥，不满足“让权等待”，浪费处理机事件

#### *信号量

- 整型信号量 
  
  - 用一个整数型的变量作为信号量用来表示系统中某种资源的数量
  
  - 不满足”让权等待”，执行wait时若S<=0，就一直测试S，不释放CPU
  
  - 在单处理机系统中，若采用整型信号量机制，一旦进程进入”忙等“，其他进程无法获取CPU使用权，严重降低系统吞吐量和资源利用率
  
  - ```c
    wait(S){
        while(S<=0);
        S--;
    }
    signal(S){
        S++;
    }
    ```

- 记录型信号量
  
  > 2014年简答题 给出数据结构定义和PV操作伪代码，说明物理意义
  
  ```c
  typedef struct{
      int value;
      struct process_control_block *list;
  }semaphore;
  void wait(semaphore *S){
      S->value--;
      if(S->value <0) block(S->list);
  }
  void signal(semaphore *S){
      S->value++;
      if(S->value<=0) wakeup(S->list);
  }
  ```
  
  信号量S的物理含义
  
  - S>0时，S表示可使用的资源数；或可使用资源的进程数；S=0时，表示无资源供使用；
  - S<0时，-S表示等待使用资源的进程数；
  - S>0时，调用P(S)的进程不会等待；调用V(S)后使可用资源数加1
  - S<0时，调用P(S)的进程必须等待；调用V(S)后将释放一个等待使用资源者

- AND型信号量集机制

- 一般信号量集机制

###### **利用记录型信号量解决同步问题（掌握）

（11年编程题：六个相互合作的进程）

（14年923四、两个进程通过一个共享文件单向传递消息）

```cpp
// P1 发送 P2 接收  假设文件最多容纳N个消息
semaphore sem = N; //定义信号来量
semaphore m = 1;// 用于互斥访问文件
// P1进程
wait(m);
sendMessage();//将消息写入到文件中
signal(sem);
signal(m);
// P2进程
wait(sem);
wait(m);
recvMessage();//从文件中读取消息
signal(m);
```

（14年923四、消息传递）

```cpp
semaphore write = 1; // 表示开始可以直接发送消息
semaphore read = 0; // 表示之前不可读，因为没写入数据呢
semaphore m = 1;
int readCount = 0;
int inReadings = 0;
//发送进程
wait(write);
sendMessage(); //发送消息
signal(read);
//读取进程
wait(m);
readCount++;
inReadings++;
if(readCount == 1) wait(read);
signal(m);
recvMessage();//读取消息
wait(m);
inReadings--; //表示某个读取完成
if(readCount == n && inReadings == 0)//表明已经有n个开始接收，并且接收完成
reaCount = 0;//准备进行下次的n次读取
signal(write);
signal(m);
```

（18年应用题：6个table，同一时刻只招待一伙客人，最多四个，一伙如果超过4个用两张table拼一起用，如果没有table，客人等待。每伙不超过8人，把客人抽象为进程）

设置资源信号量，初值为6；互斥信号量mutex，初值为1；number表示每伙客人数量

```cpp
semaphore mutex = 1,table = 6;
int number;
void guest(){
    wait(mutex);
    if(0<number<=4){
        wait(table);
        signal(mutex);
        take food;
        signal(table);
    }
    if(4<number<=8){
        if(table>=2){
            wait(table);
            wait(table);
            signal(mutex);
            take food;
            signal(table);
            signal(table);
        }
        else
            signal(mutex);
    }
}
```

#### *经典进程的同步问题

##### 生产者-消费者问题（19年应用题）

##### 哲学家进餐问题（13年927编程题）

##### 读者-写者问题（12年927编程题abc打印，09年923五，10年923五）

①允许多个读者可以同时对文件执行读操作；
②只允许一个写者往文件中写信息；
③任一写者在完成写操作之前不允许其他读者或写者工作；
④写者执行写操作前，应让己有的读者和写者全部退出。

### *管程

管程可以看做一个软件模块，它是将共享的变量和对于这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，进程可以调用管程来实现进程级别的并发控制；

进程只能互斥得使用管程，即当一个进程使用管程时，另一个进程必须等待。当一个进程使用完管程后，它必须释放管程并唤醒等待管程的某一个进程；

在管程入口处的等待队列称为入口等待队列，由于进程会执行唤醒操作，因此可能有多个等待使用管程的队列，这样的队列称为紧急队列，它的优先级高于等待队列

### *进程通信

- 共享存储
  - 基于数据结构的共享
  - 基于存储区的共享
- 消息传递
  - 直接通信方式
  - 间接通信方式
- 管道通信

顾名思义，进程通信就是指进程之间的信息交换进程是分配系统资源的单位（包括内存地址空间），因此**各进程**拥有的**内存地址空间相互独立**。

为了保证安全，一个进程不能直接访问另个进程的地址空间。

但是进程之间的信息交换又是必须实现的。

为了保证进程间的安全通信，操作系统提供了一些方法。

### 线程

#### 概念

减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。
线程是一个基本的CPU执行单元，也是程序执行流的最小单位

引入线程后，进程只作为系统资源的分配单元，线程作为处理机的分配单元。
不仅是进程之间可以并发，进程内的个线程之间也可以并发，从而进一步提升了系统的并发度。

传统的进程间并发，需要切换进程的运行环境，系统开销很大，线程间并发，如课是同一进程内的线程切换，则不需要切换进程环境，系统开销小，引入线程后，并发所带来的系统开销减小

属性：
 线程是处理机调度的单位
 多CPU计算机中，各个线程可占用不同的CPU
 每个线程都有一个线程ID、线程控制块(TCB)
 线程也有就绪、阻塞、运行三种基本状态
 线程几乎不拥有系统资源
 同一进程的不同线程间共享进程的资源
 由于共享内存地址空间，同一进程中的线程间通信甚至无需系统干预
 同一进程中的线程切换，不会引起进程切换
 不同进程中的线程切换，会引起进程切换
 切换同进程内的线程，系统开销很小
 切换进程，系统开销较大

#### 线程控制

#### *线程的同步与通信

一组数据以及定义在这组数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程

- 基本特性
  - 局部于管程的数据只能被局部于管程内的过程所访问
  - 一个进程只有通过调用管程内的过程才能进入管程访问共享数据
  - 每次仅允许一个进程在管程内执行某个内部过程

#### 线程的实现方式*

用户级线程：有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。
内核级线程：线程的管理工作全部由内核完成

### 处理机调度

#### 调度的层次

**进程调度（低级调度/处理机调度）**：按照某种策略或者方法从就绪队列中选取一个进程，将处理机分配给它(最基本的调度，频率很高)。

**内存调度（中级调度）**：提高内存利用率和系统吞吐量，将暂时不能运行的进程调至外存，使其进入挂起态。或者将已经具备运行条件的进程调入内存，修改其状态为就绪态。

**作业调度（高级调度）**：从外存中选择作业送入内存并分配资源，并建立相应的进程，以使它们获得竞争处理机的权，每个作业只调入一次，调出一次。

**磁盘调度**：磁盘调度在多道程序设计的计算机系统中，各个进程可能会不断提出不同的对磁盘进行读写操作的请求。由于有时候这些进程的发送请求的速度比磁盘响应的还要快，因此有必要为每个磁盘设备建立一个等待队列。

页面置换算法：进程运行时，若其访问的页面不在内存而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区选择调出页。

进程调度、磁盘调度频率较高，是操作系统必不可少的;
作业调度、内存调度较进程调度频率小很多，而且不是操作系统必不可少的;
页面置换算法 频率不会较高，因为如果频率过高说明不是一个好的页面置换算法，且只在虚拟内存管理中存在，因此也不是必不可少的。

#### 进程调度方式

#### 处理机调度实现机理*

#### 调度算法的评价指标*

- CPU 利用率

- 系统吞吐量

- 周转时间
  
  - 周转时间、平均周转时间
  - 带权周转时间、平均带权周转时间

- 等待时间

- 响应时间

#### 处理机主要调度算法设计实现及应用（掌握）

###### 先来先服务调度算法 (First Come First Serve)

思想：从公平的角度考虑
规则：按进程到达的先后顺序进行服务
用于作业调度时，考虑的是哪个作业先到达后备队列；用于进程调度时，考虑的是哪个进程先到达就绪队列

非抢占式算法
优点：公平、算法实现简单
缺点：排在长作业后面的短作业需要等待很长时间，带权周转时间很大，对短作业来说用户体验不好

不会导致饥饿

###### 短作业优先调度算法 (Short Job First)

思想：追求最少的平均等待时间、最少的平均周转时间、最少的平均带权周转时间，作业调度、进程调度都可用。
规则：最短的作业/进程优先得到服务

进程调度时称为“短进程优先（Shortest Process First）算法” SPF

非抢占式，抢占的叫做”最短剩余时间优先算法“（Shortest Remaining Time Next) SPTN
优点：最短的平均等待时间、平均周转时间
缺点：不公平。对短作业有利，对长作业不利，可能导致饥饿现象

###### 高响应比优先调度算法 (Highest Response Ratio Next)

思想：综合考虑进程的等待时间和要求服务的时间，作业调度、进程调度都可用。

规则：只有当前运行的进程主动放弃CPU时，才需要进行调度，计算所有就绪进程的响应比，选择最高的进程上处理机，响应比=$\frac{等待时间+要求服务时间}{要求服务时间}$

非抢占式，只有当前运行的进程主动放弃CPU时，才需要进行调度，才需要计算响应比。

优点：综合考虑了等待时间和运行时间。
等待时间相同时，服务时间短的优先。服务时间相同时，等待时间长的优先。
对于长作业来说，等待时间越来越久，响应比也会变大，避免了长作业饥饿的问题。

###### 时间片轮转调度算法（Round-Robin）

思想：公平地、轮流地为各个进程服务，让每个进程在一定时间间隔内都得到响应。
        只能用于进程调度（只有作业放入内存建立了进程后才能被分配处理机时间片。）

规则：按照各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片。若未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列队尾排队。

抢占式。 若进程未能在时间片内运行完，将被强行剥夺处理机使用权，由时钟装置发出时钟中断来通知CPU时间片已到。

优点：公平；响应快，适用于分时操作系统
缺点：由于高频率的进程切换，因此有一定开销；不区分任务紧急程度。

不会导致饥饿

如果时间片太大，使得每个进程都可以在一个时间片内就完成，则时间片轮转调度算法退化为先来先服务调度算法，并且会增大进程响应时间。因此时间片不能太大。
另一方面，进程调度、切换是有时间代价的(保存、恢复运行环境)，因此如果时间片太小，会导致进程切换过于频繁，系统会花大量的时间来处理进程切换，从而导致实际用于进程执行的时间比例减少，可见时间片也不能太小。

一般来说，设计时间片要让切换进程的开销占比不超过1%

###### 优先级调度算法

思想：根据任务的紧急程度来决定处理顺序，作业调度、进程调度都可用。

规则：每个作业或进程有各自优先级，调度时选择优先级最高的。

抢占式、非抢占式都有。做题时的区别在于：非抢占式只需在进程主动放弃处理机时进行调度即可，而抢占式还需在就绪队列变化时，检查是否会发生抢占。

优点：用优先级区分紧急程度、重要程度，适用于实时作系统。可灵活地调整对各种作业/进程的偏好程度。
缺点：若源源不断地有高优先级进程到来，则可能导致饥饿

###### 多级反馈队列调度算法

思想：对其他调度算法的折中权衡，用于进程调度

规则：
    1.设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
    2.新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片，
        若用完时间片进程还未结束，则进程进入下一级队列队尾。
        如果此时已经是在最下级的队列，则重新放回该队列队尾。
    3.只有第k级队列为空时，才会为k+1级队头的进程分配时间片

抢占式。可能会导致饥饿

- 对各类型进程相对公平（FCFS 的优点）
- 每个新到达的进程都可以很快就得到响应（RR 的优点）
- 短进程只用较少的时间就可完成（SPF 的优点）
- 不必实现估计进程的运行时间（避免用户作假）
- 可灵活地调整对各类进程的偏好程度，比如 CPU 密集型进程、I/O 密集型进程

> 拓展：可以将因 I/O 而阻塞的进程重新放回原队列，这样 I/O 型进程就可以保持较高优先级。

为什么多级反馈队列调度算法能较好地满足各种类型用户的需要？

对终端型作业用户而言，由于它们提交的作业大多属于交互型作业，作业通常比较短小，系统只要能使这些作业在第1级队列所规定的时间片内完成，便可使终端型作业用户感到满意；

对短批处理作业用户而言，它们的作业开始时像终端型作业一样，若仅在第1级队列中执行一个时间片即可完成，便可获得与终端型作业一样的响应时间，对于稍长的作业，通常也只需要在第2级队列和第3级队列中各执行一个时间片即可完成，其周转时间仍然较短；

对于长批处理作业用户而言，它们的长作业将一次在第1，2，…，n级队列中运行，然后按时间片轮转方式运行，用户不必担心其作业长期得不到处理。

### 死锁

##### *死锁及处理方法；

什么是死锁：多个进程都在等待其他进程才能引发的事件，那么该组进程是死锁的。

（13年927名词解释）

###### 产生死锁的原因：

①竞争资源 ②进程推进次序不当

###### 产生死锁的必要条件：

1. 互斥条件：进程对分配的资源进行排他性控制
   只有对必须互斥使用的资源的争抢才会导致死锁，有时应该保护互斥性
2. 不可剥夺条件：进程获得资源在未使用完之前，不能被其他进程强行夺走
3. 请求并保持条件：进程已经保持了至少一个资源，提出新的资源请求，而该资源已经被其他进程占有，此时该进程被阻塞，但是自己已经获得的资源保持不放
4. 循环等待条件：你等我释放 我等你释放

###### 死锁的预防方法：

①破坏“请求和保持”——申请和分配资源均为一次性
    特点：实现简单，但是资源被严重浪费，可能导致进程饥饿
②破坏“不可剥夺”——请求未果，放弃
    特点：实现复杂；剥夺资源可能导致部分工作失效；系统开销大；可能导致饥饿
③破坏“循环等待”——资源按序分配
    特点：进程编号必须稳定，可能导致资源浪费，不利于用户编程

##### *银行家算法给出避免死锁的资源分配方案（掌握）

银行家算法步骤：
①检查此次申请是否超过了之前声明的最大需求数
②检查此时系统剩余的可用资源是否还能满足这次请求
③试探着分配，更改各数据结构
④用安全性算法检查此次分配是否会导致系统进入不安全状态

安全性算法步骤：
检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可以，就把该进程加入安全序列并把该进程持有的资源全部回收。
不断重复上述过程，看最终是否能让所有进程都加入安全序列。

系统处于不安全状态未必死锁，但死锁时一定处于不安全状态。系统处于安全状态一定不会死锁

（09年923六、13年923二.1、14年三、）

##### *死锁检测算法及应用（掌握）

依次消除与不阻塞进程相连的边，直到无边可消

死锁定理：若资源分配图是不可完全简化的，说明发生了死锁

为了能对系统是否已发生了死锁进行检测，必须：
①用某种数据结构来保存资源的请求和分配信息；
②提供一种算法，利用上述信息来检测系统是否已进入死锁状态。

（10年五、

##### 死锁的接触

资源剥夺法：从其他进程中抢占足够的资源给死锁的进程以解除其死锁状态

撤销进程法：撤销一些进程，直到有足够的资源分配给其他进程，进程死锁状态

进程回退法：让一个或多个进程回退到足以避免死锁的地步，进程回退时资源释放资源而不是被剥夺，要求系统保持进程的历史信息，设置还原点

---

## 第三章 内存管理

#### 3.1 内存管理基础

##### 程序处理

编译、链接、装入

创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：

- 编译：由编译程序将用户源代码编译成若干个目标模块。
- 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。（11年923简答：什么是链接？链接主要解决了什么问题？链接的主要类型及其优缺点是什么）
- 装入：由装入程序将装入模块装入内存运行。

程序的链接有以下三种方式：

- 静态链接：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。
- 装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。
- 运行时动态链接：对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。

##### 内存管理

###### 内存空间的分配与回收

###### 地址转换

###### 内存空间的扩充

###### 内存保护

内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。通过釆用重定位寄存器和界地址寄存器来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。（11年923简答：重定位：装入时对目标程序中指令和数据的修改过程）

##### 分区存储管理及相关扩充技术

###### 拼凑

###### 覆盖

解决“程序大小超过物理内存综合”的问题

必须由程序员声明覆盖结构，操作系统自动完成覆盖，对用户不透明

基本思想：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。  

特点：打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行。

###### 对换

交换（对换）技术的设计思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中
某些已具备运行条件的进程换入内存（进程在内存与磁盘间动态调度）

##### 连续分配管理

###### 单一连续分配

###### 固定分区分配

###### *动态分区存储管理设计与实现（掌握）

基本思想：根据进程的实际需求，动态地对内存空间进行分配、回收及划分

优点：分区大小可以根据进程的实际情况进行分配
缺点：存在外部碎片，最后导致主存利用率下降

动态分配算法：

- 首次适应算法（First Fit, FF）
  
  - 空闲分区按照地址递增的顺序进行查找，找到第一个满足要求的分区进行分配
    优点：综合看性能最好。算法开销小，回收分区后一般不需要对空闲分区队列重新排序

- 最佳适应算法（Best Fit, BF）
  
  - 按照容量递增的顺序进行查找分区，将第一个满足条件的进行分配
  - 优点：第一次找到的空闲分区是大小最接近待分配内存作业大小的；
  - 缺点：性能较差，产生大量难以利用的外部碎片
  - 回收分区后可能需要对空闲分区队列重新排序

- 最坏适应算法（Worst Fit, WF）
  
  - 空闲分区按照容量递减的次序进行查找，第一个满足条件的进行分配
  - 优点：效率高，分区查找方便减少难以利用的小碎片
    缺点：导致很快没有较大的内存块，性能很差，不利于大进程，算法开销大

- 循环首次适应算法（Next Fit, NF）（邻近适应算法）
  
  - 分配内存时从上次查找结束的位置开始继续查找
  - 优点：算法开销小，使得空闲分区分布更加均匀
    缺点：高址部分的大空闲分区被分小，使得大作业进入无法分配内存；

- ###### 伙伴系统（基于索引搜索的动态分区分配算法）
  
  伙伴系统是连续存储分配的一种办法。它比较好地折中了分配和回收过程中分配块的位置碎片和合并的问题。
  
  - 整个可分配的分区大小2^u
  - 需要的分区大小为2^{u-1}
  - 如s\le 2^{i-1}-1 ，将大小为2^u 的当前空闲分区划分成两个大小为2^{i-1}-1 的空闲分区
  - 重复划分过程，直到2^{i-1}-1

##### *非连续分配管理

> 掌握 分页/分段地址变换

###### 基本分页存储管理

分页管理方式是从计算机的角度考虑设计的，以提高内存的利用率，提升计算机的性能, 且分页通过硬件机制实现，对用户完全透明；

思想：把主存空间划分为大小相等的块，块相对较小，作为主存的基本单元。每个进程也以块为单位划分，进程执行时，以块为单位申请内存空间

<u>**具有快表的地址变换机构**</u>   

*反置页表

###### 基本分段存储管理

分段管理方式的提出则是考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。

进程的地址空间：按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名（在低级语言中，程序员使用段名来编程），每段从0开始编址

内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻 

段表分为：
段号+段长+本段在主存的起始地址

地址变换过程如下：

- 从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。
- 比较段号S和段表长度M，若S多M，则产生越界中断，否则继续执行。
- 段表中段号S对应的段表项地址 = 段表起始地址F + 段号S * 段表项长度，取出该段表项的前几位得到段长C。若段内偏移量>=C，则产生越界中断，否则继续执行。
- 取出段表项中该段的起始地址b，计算 E = b + W，用得到的物理地址E去访问内存。

###### 段页式存储管理

分页管理
优点：内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片
缺点：不方便按照逻辑模块实现信息的共享和保护
分段管理
优点：很方便按照逻辑模块实现信息的共享和保护
缺点：如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理会产生外部碎片

在段页式系统中，作业的地址空间首先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分成若干个大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干个和页面大小相同的存储块，对内存的分配以存储块为单位

段号的位数决定了每个进程最多可以分几个段
页号位数决定了每个段最大有多少页
页内偏移量决定了页面大小、内存块大小是多少

段表项：段号+页表长度+页表存放块号，段号隐藏

**<u>地址变换</u>** 

1.由逻辑地址得到段号、页号、页内偏移量
2.段号与段表寄存器中的段长度比较，检查是否越界
3.由段表始址、段号找到对应段表项
4.根据段表中记录的页表长度，检查页号是否越界
5.由段表中的页表地址、页号得到查询页表，找到相应页表项
6,由页面存放的内存块号、页内偏移量得到最终的物理地址
7.访问目标单元

#### 3.2 虚拟内存管理

##### *虚拟存储技术

###### 传统存储管理方式的特征

- 一次性
  
  作业必须一次性全部装入内存后，方能开始运行。这会导致两种情况发生：
  
  - 当作业很大，不能全部被装入内存时，将使该作业无法运行；
  - 当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降。

- 驻留性
  
  - 一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。

###### 局部性原理

- 时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行：如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循环）

- 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。
空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。
虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。

###### 虚拟内存的定义和特征

        基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。
        在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。
        若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。
        在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存

虚拟存储器有以下三个主要特征：

- 多次性，是指无需在作业运行时一次性地全部装入内存，而是允许被分成多次调入内存运行。
- 对换性，是指无需在作业运行时一直常驻内存，而是允许在作业的运行过程中，进行换进和换出。
- 虚拟性，是指从逻辑上扩充内存的容量，使用户所看到的内存容量，远大于实际的内存容量。

###### 虚拟内存技术的实现

虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式：

- 请求分页存储管理。
- 请求分段存储管理。
- 请求段页式存储管理。

##### *请求分页/分段存储管理

> 为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。

###### 页表机制

![](https://img2020.cnblogs.com/blog/727485/202107/727485-20210705150900839-215697525.png)

四个字段说明如下：

- 状态位P：用于指示该页是否已调入内存，供程序访问时参考。
- 访问字段A：用于记录本页在一段时间内被访问的次数，或记录本页最近己有多长时间未被访问，供置换算法换出页面时参考。
- 修改位M：标识该页在调入内存后是否被修改过。
- 外存地址：用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。

###### 缺页中断机构

所要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒)，如果内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存)。  

缺页中断与一般的中断相比，它有以下两个明显的区别：

- 在指令执行期间产生和处理中断信号，而非一条指令执行完后，属于内部中断。
- 一条指令在执行期间，可能产生多次缺页中断。

###### 地址变换（掌握）

![](https://img2020.cnblogs.com/blog/727485/202107/727485-20210705150930175-80399221.png)

先检索快表：

- 若找到要访问的页，便修改页表项中的访问位（写指令则还须重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址。
- 若未找到该页的页表项，应到内存中去查找页表，再对比页表项中的状态位P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。

##### *页面淘汰算法设计实现及应用（掌握）

###### **1.最佳置换算法(OPT)**

每次选择的被淘汰页面将是<u>**以后永不使用**</u>的，或者是<u>**在最长时间内不再被访问的页面**</u>,这样可以保证获得<u>**最低的缺页率**</u>。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。

###### **2. 先进先出(FIFO)页面置换算法**

淘汰最早进入内存的页面，亦即在内存中驻留时间最久的页面。

实现方法：把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。

Belady异常一一当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。
只有FIFO算法会产生Belady异常。另外，FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此，算法性能差

###### **3. 最近最久未使用(LRU)置换算法**

淘汰最近最长时间未访问过的页面

实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。

该算法的实现需要专门的硬件支持，虽然算法性能好但是实现困难，开销大，需要寄存器和栈的硬件支持。LRU是堆栈类的算法

###### **4. 时钟(CLOCK)置换算法（最近未用(Not Recently Used, NRU)算法）**

简单的CLOCK算法实现方法：为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成
一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出：如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择一个淘汰页面最多会经过两轮扫描）

改进型的CLOCK置换算法：增加一个修改位

每一帧都处于以下四种情况之一：

1. 最近未被访问，也未被修改(u=0, m=0)。
2. 最近被访问，但未被修改(u=1, m=0)。
3. 最近未被访问，但被修改(u=0, m=1)。
4. 最近被访问，被修改(u=1, m=1)。
5. 改进型的CLOCK算法优于简单CLOCK算法之处在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。

---

## 第四章 设备管理

#### I/O系统组成

##### I/O系统结构

微机总线型I/O系统结构

主机通道型I/O系统结构

##### I/O设备分类

- 按数据传输速率分类
  
  - 高速设备、中速设备、低速设备

- 按信息交换单位分类
  
  - 块设备(传输速率高、可寻址、DMA)
  
  - 字符设备(传输速率低、不可寻址、中断)

- 按设备共享属性分类
  
  - 独占设备
  
  - 共享设备

##### 设备控制器

概念

- 设备控制器是主机与外围设备之间的接口，是一个可编址设备，每一个地址对应一个设备。它接收从CPU发来的命令，并去控制输入输出设备的工作，使CPU从繁杂的设备控制事务中解脱出来，提高CPU的使用效率。

- 设备标识：系统按为每台设备分配惟一的号码，用做硬件（设备控制器）区分和识别设备的代号，称做设备绝对号（或绝对地址）。操作系统为每类设备也规定了一个编号，称做设备类型号。如在UNIX系统中，设备类型号也称做主设备号。

功能：

- 接收和识别命令
  
  - 控制寄存器/命令译码器

- 数据交换（数据寄存器）

- 标识和报告设备状态（状态寄存器）

- 地址识别（地址译码器）

- 数据缓冲（缓冲器）

- 差错控制（差错检查码）

设备控制器的组成

1）CPU与设备控制器的接口。该接口用于实现CPU与设备控制器之间的通信。共有三类信号线：数据线、地址线和控制线。
2）设备控制器与设备的接口。控制器中的输入输出逻辑根据处理器发送来的地址信号，去选择一个设备接口。一个设备接口连接一台设备。
3）I/O逻辑。用于实现对输入输出设备的控制。

![](C:\Users\17131\AppData\Roaming\marktext\images\2022-07-20-15-51-12-image.png)

##### I/O通道

概念

- 通道：一种特殊的专门执行I/O指令的处理机，与CPU共享内存，有自己的指令系统，能按照执行的要求独立完成I/O 操作。
- 引入目的：解脱CPU对I/O的组织、管理，使CPU与外设能够并行工作。
- 工作方式：CPU只需发送I/O命令给通道，通道通过调用内存中的相应通道程序完成任务。

分类

- 1）字节多路通道：字节多路通道连接多个字符设备（低中速设备），不会丢失信息。
  数量可以从几十到数百个。
  
  - 含有许多非分配型子通道，各个设备按时间片轮转方式（同步时分多路复用）共享通道。

- 2）数组选择通道：可以连接多台高速设备。
  
  - 不划分子通道，只有一个分配型子通道。
  
  - 有很高的传输速率，但是，它每次只允许一个设备传输数据，通道独占且利用率很低。

- 3）数组多路通道：用于连接多台高、中速的外围设备，其数据传送是按数组方式进行的。
  
  - 含有多个非分配型子通道，时间片轮转方式（同步时分多路复用）共享通道。既具有很高的数据传输速率，又有令人满意的通道利用率。

瓶颈

        由于通道价格昂贵，致使机器中所设置的通道数量势必较少，这往往又使它成了/O
的瓶颈，进而造成整个系统吞吐量的下降。

        解决办法：增加设备到主机间的通路而不增加通道

#### I/O控制方式

##### 程序性I/O控制方式

最原始的“忙-等”控制方式设备管理程序用于控制与管理实现信息输入、输出和存储的设备。由于/O设备不仅种类繁多，而且彼此特性和操作方式相差较大，从而使设备管理成为操作系统中最繁杂且与硬件紧密相关的部分
主要目标
方便用户使用，实现对不同类型设备的统一管理、使用并协调各台外围设备的并发运作
提高系统/O效率，缓解CPU和各种不同处理速度的外围设备之间的矛盾
设备管理的可扩充性，包括设备的增加和删除以及对新的设备类型的适应性

只适用于CPU速度较慢，而且外围设备较少的系统，主要用于早期无中断的计算机系统。

缺点：

1）CPU和外围设备只能串行工作。由于CPU的处理速度大大高于外围设备的数据传送和处理速度，所以，CPU的大量时间都处于等待和空闲状态，使CPU的利用率大大降低；
2）CPU在一段时间内只能和一台外围设备交换数据信息，从而不能实现设备之间的并行工作；
3）由于程序直接控制方式依靠测试设备标志触发器的状态位来控制数据传送，因此无法发现和处理由于设备或其它硬件所产生的错误。

##### 中断驱动型I/O控制方式

引入中断机制，允许CPU在等待时间做其他事情

基本原理：

- 为了减少程序直接控制方式中CPU等待时间，以及提高系统的并行工作程度，中断控制方式被用来控制外围设备和内存与CPU之间的数据传送。这种方式要求CPU与设备（或控制器）之间有相应的中断请求线，而且在设备控制器的控制状态寄存器有相应的中断允许位。

- 中断方式下，包括以后其它的方式，设备控制器都能够主动向CPU发出中断信号，获得CPU的处理。

##### 直接内存存取型I/O控制方式（Direct Memory Access）

CPU直接指挥DMA控制器，从DMA控制器取数据，数据传输单位更大

##### 通道型I/O控制方式

通道程序负责执行对设备的指令，使通道、IO操作、数据传送独立

基本原理：

- 通道控制方式与DMA方式相类似，也是一种以内存为中心，实现设备和内存直接交换数据的控制方式。不同的是DMA方式中，数据的传送方向、存放数据的内存始址以及传送的数据块长度等都由CPU控制，而在通道方式中，这些都由专管输入/输出的硬件 — 通道来进行控制。

- 此外，DMA方式时一个DMA控制器一般连接一台设备，而通道控制方式可以做到一个通道控制多台设备与内存进行数据交换，从而，通道方式进一步减轻了CPU的工作负担，增加了计算机系统的并行工作程度。

- 通道是一个独立于CPU的专用的输入/输出处理机，它控制设备与内存直接进行数据交换，有自己的通道指令，这些通道指令受CPU启动，在操作结束时向CPU发中断信号。

#### 设备管理目标、功能及层次结构

##### 设备管理及设计目标、功能

- 设备管理程序用于控制与管理实现信息输入、输出和存储的设备。由于/O设备不仅种类繁多，而且彼此特性和操作方式相差较大，从而使设备管理成为操作系统中最繁杂且与硬件紧密相关的部分

- 主要目标
  
  - 方便用户使用，实现对不同类型设备的统一管理、使用并协调各台外围设备的并发运作
  
  - 提高系统/O效率，缓解CPU和各种不同处理速度的外围设备之间的矛盾
  
  - 设备管理的可扩充性，包括设备的增加和删除以及对新的设备类型的适应性

- 功能
  
  - 提供设备使用的用户接口
    
    - 命令接口和编程接口
  
  - 设备分配和释放
    
    - 分配设备及相应的通道、设备控制器
  
  - 设备的访问和控制
    
    - 并发访问及差错处理
  
  - I/O缓冲和调度
    
    - 提高I/O访问效率，缓解CPU与外设矛盾

##### 设备管理层次结构

- 用户空间I/O请求支持层
  
  - 提供对逻辑设备的控制。具体来说，针对用户接口，提供抽象的命令，如Open,Close,Read,Vrite;针对通信设备，提供通信体系结构如网络协议栈；针对文件存储设备，提供文件系统的逻辑结构控制。

- 设备独立性软件层
  
  - 逻辑设备与物理设备间过渡协调机构，实现用户命令到设备操作序列的转换，提供缓冲机制

- 设备调度和控制层
  
  - 实现硬件物理设备的设备驱动、设备控制、状态维护、中断处理及并发/O访问调度

#### 缓冲管理

###### 引入原因

- 缓和CPU与/O设备速度不匹配的矛盾

- 减少对CPU的中断频率，放宽对中断响应时间的限制

- 提高CPU与/O设备之间的并行性

###### 主要功能

- 缓冲区的组织

- 缓冲区的获得与释放

##### 单缓冲

##### 双缓冲

##### 循环缓冲

- 缓冲区使用过程
  
  - GetBuf(BufType,Current)过程
  
  - REleaseBuf(BufType,Current)过程

##### 缓冲池

#### 设备分配

##### 设备分配相关数据结构

- 系统设备表：记录系统全部设备的情况

- 设备控制表：针对每台设备而设置和记录对应情况

- 设备控制器控制表：针对每个设备控制器而设置和记录对应情况

- 通道控制板：针对每个通道而设置和记录对应情况

##### 设备分配考虑因素

###### 设备分配考虑因素

- 设备的固有属性 独占/共享/虚拟设备 

- 设备分配算法 ：先来先服务/优先级高者优先 

- <u>设备分配中的安全性</u>：安全分配方式/不安全分配方式 

- 设备独立性：用户和应用程序输入输出请求独立于物理设备

###### 设备分配中的安全性

- 安全分配方式 
  
  - 每当进程发出/O请求和获得某种设备（资源）后便进入阻塞状态（使其不可能再请求任何资源而在它运行时又不保持任何资源），直到其/O操作完成时才被唤醒 
  
  - 分配安全，但CPU与引/O设备串行工作，进展慢 

- 不安全分配方式 
  
  - 进程发出/O请求后仍继续运行，需要时又可发出第二、第三个I/O请求；仅当进程所请求的设备已被另一进程占用时，进程才进入阻塞状态 
  
  - 同一进程可同时操作多台设备，故推进迅速 
  
  - 为避免死锁，需进行安全性计算

##### 设备独立性

###### 概念

- 应用程序独立于具体使用的物理设备

- 应用程序以逻辑设备名称来请求使用某类设备；系统实际执行时则使用物理设备名称

###### 目标

- 设备分配时的灵活性、可扩展性/适应性

- 易于实现I/O重定向（即用于I/O操作的设备可以随时更换，而不必改变应用程序）、

###### 逻辑设备名到物理设备名的映射

###### 设备管理层次结构

用户进程和硬件之间的层次结构

- 用户空间I/O请求支持层

- <u>设备独立性软件层</u>

- 设备调度与控制层

###### 设备独立性软件

- 向用户空间I/O请求支持层软件提供统一接口

- 执行所有设备的公有操作
  
  - （独占/块）设备的分配与回收
  
  - 逻辑设备到物理设备的映射（驱动程序）
  
  - 一维逻辑盘块号到一维物理盘块号的转换
  
  - 缓冲管理
  
  - 设备保护
  
  - 差错控制

> 2011年二.设备独立性（名词解释）（2分）

##### 独占设备分配流程

对于具有I/O通道的系统，在进程提出I/O请求后，系统的设备分配程序可按下述步骤进行设备分配：

- 分配设备

- 分配设备控制器

- 分配通道 

##### 假脱机技术（SPOOLing技术）

###### 将一台独占设备改造成共享设备

###### SPOOLing系统的组成

建立在具有多道程序功能的操作系统上，且应有告诉随机外存（磁盘存储技术）的支持

---

- 输入井（输出井）：磁盘上用以收容输入（或输出）数据的存储空间

- 输入缓冲区（输出缓冲区）：内存种用以暂存输入（或输出）数据的存储空间

- 输入进程$SP_i$（或输出进程$SP_o$ ）：模拟脱机输入（或输出）时的外围控制机

- 请求输入队列（请求输出队列）：由用户请求输入（或输出）表构成

###### 共享打印机

广泛应用于多用户系统和局域网络中

1. 用户进程提出打印输出请求，唤醒打印守护进程

2. 打印守护进程在输出井中为之申请一空闲盘块区并将要打印的数据送入其中

3. 打印守护进程为用户进程申请一张空白的用户请求打印表，并将用户打印要求填入其中和把该表挂到请求打印队列上

4. 打印守护进程视打印机空闲与否从请求打印队列队首取出一张用户请求打印表，并按对应要求将打印数据从输出井传送到内存缓冲区和打印

5. 打印守护进程在请求打印队列为空时将阻塞自己，直到再次有打印请求出现时才被唤醒

###### SPOOLing系统的特点

- 提高了I/O的速度
  
  - 数据I/O操作演化为对输入/输出井的存取
  
  - CPU数据处理与设备I/O操作的并行化

- 将独占设备改造为共享设备
  
  - 设备分配实质为在输入/输出井中为用户进程分配一空闲盘块区及建立一章输入/输出请求表

- 实现了虚拟设备功能
  
  - 一台独占设备变换为若干台逻辑独占设备

> 2011年927七. 什么技术？简述利用其打印的系统组成、工作原理及其特点

> 2012年927四.5 为什么要引入SPOOLing系统？SPOOLing系统带来哪些好处？（10分）
> 
> 2013年927二.5 SPOOLing系统（名词解释）

> 2013年三.3 简述利用假脱机技术实现打印机共享的基本处理过程（5分）

> 2017年7.  采用假脱机技术来实现打印机共享，需要（多选）
> 
> 1. 设置内存缓冲区暂存从输出井传送来的准备打印输出的数据
> 
> 2. 在磁盘上设立输出井用来收容准备打印输出的数据
> 
> 3. 接受用户打印输出请求并将之插入到打印请求队列
> 
> 4. 处理打印请求队列的各项打印请求并实施打印操作 

> 2020年四.3  假脱机技术实现打印机共享方案（包括基本系统组成及打印请求处理过程）（7分）
> 
> 基本系统组成：
> 
> - 输入井和输出井
> 
> - 输入缓冲区和输出缓冲区
> 
> - 输入进程和输出进程
> 
> 打印请求处理过程：
> 
>         用户进程请求打印输出时，SPOOLing系统立即同意为该进程执行打印输出，但并不是立即把打印机分配给该用户进程，而只是为该进程做两项工作：①输出进程在输出井中申请一个空闲盘块，并将要打印的数据送入其中暂存；②为用户进程申请申请一张空白的用户请求打印表，并将用户的打印要求填入其中，再将该表挂到打印机的请求队列上。如果还有另外的进程请求打印机，系统仍同意为该进程执行打印输出。
> 
>         实际打印时，如果打印机空闲，输出进程将从请求打印队列的队首摘取一张请求打印表，根据表中要求将要打印的数据由输出井送到内存缓冲区，再交付打印机打印。打印完成后，输出进程再检查请求打印队列，若队列非空，重复打印，直至队列为空，然后输出进程将自己阻塞起来，当再次有打印请求时被重新唤醒运行。

#### 设备驱动及中断处理

###### 设备处理程序的功能

1. 接收由/O请求进程发来的命令和参数，并将命令中的抽象要求转化为具体要求

2. 检查用户/O请求的合法性

3. 检查/O设备状态，若忙则挂在设备队列上等待

4. 传递和设置/O设备的有关参数与工作方式，包括根据用户/O请求构造必要的通道程序

5. 发出/O命令，启动分配到的/O设备去完成指定的/O操作

6. 及时响应来自通道或设备控制器的中断请求，并根据其中断类型调用相应中断处理程序进行处理

###### 设备处理方式

- 根据设备处理时是否设置进程及设置什么样的进程而划分
  
  - 为每一类设备设置一个进程
  
  - 整个系统设置一个I/O进程，或者设置一个输入进程和一个输出进程
  
  - 不设置专门的设备处理进程，而是只为各类设备设置响应的设备处理程序供设备独立性软件和中断处理程序调用

###### 设备处理程序的特点

- 用于I/O请求进程与设备控制器间通信

- 与I/O设备特性紧密相关：不同类型设备应配置不同驱动程序

- 与I/O控制方式紧密相关：中断驱动型/DMA型/通道型

- 与硬件紧密相关，故部分程序代码必须用汇编语言书写，且基本部分可固化和存放于ROM

###### 设备驱动过程

- 化抽象I/O操作请求为具体要求

- 检查用户I/O请求的合法性

- 检查I/O设备状态，判断是否可用

- 传递和设置I/O设备的有关参数与工作方式，包括根据用户I/O请求构造必要的通道程序

- 发出I/O命令，启动分配到的I/O设备
  
  - 基本的I/O操作是在设备控制器或通道的控制下进行的，鉴于通常I/O操作所要完成的工作较多且需要一定时间，故此时驱动（程序）进程应阻塞自己直至中断到来时才将它唤醒

###### 中断处理程序的处理过程

![](C:\Users\17131\AppData\Roaming\marktext\images\2022-07-21-21-35-42-image.png)

> 2016年923三.1.简要阐明什么是设备驱动程序；2.简要说明设备驱动程序和普通应用程序为什么会有不同（12分）
> 
> 1.设备驱动程序接受上层软件发来的抽象I/O请求，转换为具体要求发给设备控制器，启动设备区执行；反之，也将设备控制器发来的信号传送给上层软件
> 
> 2.因为设备驱动程序与硬件紧密相关，运行在内核空间，库函数位于驱动程序的上层，应用程序的下层，因此驱动程序不能调用库函数

> 2017年923一.13 设备驱动程序的功能包括（多选 2分）

> 2020年六.2 关于中断处理程序、设备驱动程序的一些流程

#### 磁盘存储器管理方法与技术

##### 磁盘存储器及管理任务

###### 磁盘存储器

- 容量大、存取速度快，且可实现随机存取

- 实现<u>**虚拟存储器/虚拟设备**</u>的必需硬件

- 存放（程序和数据）文件的主要外存设备

###### 磁盘存储器管理的主要任务

- 为文件分配必要的存储空间，使各得其所

- 合理组织文件存取方式，以提高文件访问速度

- 提高磁盘存储空间的利用率

- 提高磁盘I/O速度，以改善文件系统性能

- 采取必要的冗余措施，确保文件系统的可靠性

###### 数据的组织和格式

![](C:\Users\17131\AppData\Roaming\marktext\images\2022-07-21-22-37-45-image.png)

###### 磁盘的类型

- 硬盘和软盘、单片盘和多片盘

- 固定头磁盘

- 活动头磁盘

##### 移动头磁盘访问时间构成

- 寻道时间$T_s$ ：把磁头从当前位置移动到指定磁道上所经历的时间$T_s=m\times n+s$ 

- 旋转延迟时间$T_r$ ：指定扇区旋转到磁头下面所经历的时间$T_r=\frac{1}{2r}$  

- 数据传输时间$T_t$ ：把数据从磁盘读出或向磁盘写入数据所经历的时间$T_r=\frac{bytes}{r\times bytesPerTrack}$ 

访问时间中，数据传输时间所占比例相当小，而寻道时间和旋转延迟时间基本上均与所读写的数据量无关，所以适当地集中数据传输将有利于提高传输效率

##### 磁盘调度算法设计及应用（掌握）

磁盘调度目标：磁盘是可被多个进程共享的设备，当有多个进程请求访问磁盘时，应采用一种适当的调度算法，使各进程对磁盘的平均访问时间最小

###### 先来先服务调度算法 (FirstComeFirstService)

- 基本思想：根据进程请求访问磁盘的先后次序进行调度，优点是公平、简单，每个进程的请求都能一次得到处理，但寻道时间可能较长

###### 最短寻道时间优先调度算法(ShortestSeekTimeFirst)

- 基本思想
  
  - 选择所访问磁道与磁头当前所在磁道距离最近的进程优先调度，但不能保证平均寻道时间最短
  
  - 具较好的寻道性能，但可能导致进程饥饿现象

###### 扫描算法SCAN

- 基本思想
  
  - 不仅考虑欲访问磁道与磁头当前所在磁道的间距更优先考虑的是磁头当前移动的方向
  
  - 既能获得较好的寻道性，又能防止进程饥饿，广泛用于大中小型机及网络中

###### 循环扫描算法CSCAN

- 基本思想：规定磁头单向移动，避免某些进程磁盘请求的严重延迟

###### N-步扫描算法（N-Step-SCAN）

克服前述调度算法均具的磁臂粘着现象即磁臂停留在某处不动的情况（特别是高密度磁盘）

将磁盘请求队列分成若干个长度为N的子队列，按先来先服务算法依次处理这些子队列，而各队列以扫描算法处理（新请求放入后面队列）

###### FSCAN算法

实质为N-步扫描算法的简化，将磁盘请求队列分成
两个子队列：

①当前所有请求磁盘1/O的进程形成的队列，按扫描算法处理；

②在扫描期间新出现的所有请求磁盘/O进程形成的等待队列，本次扫描
结束后②添加到①的队尾，从而使所有新要求都被推迟到下一次扫描时处理

##### 磁盘高速缓冲及其它提高磁盘访问效率的方法

概念：设置冗余部件以提高系统可靠性

- 低级磁盘容错技术SFT-I
  
  - 双份目录与双份文件分配表
  
  - 热修复重定向、写后读校验

- 中级磁盘容错技术SFT-II
  
  - 磁盘镜像与磁盘双工

廉价磁盘冗余阵列RAID

#### 磁盘数据访问过程及时间开销(掌握)

## 第五章 文件管理

> （1）理解：文件及典型存取操作逻辑流程，文件系统层次模型，文件的逻辑结构和物理结构，外存空间管理方法，文件目录结构及管理，文件共享与保护，磁盘容错技术，文件系统性能改善策略及数据一致性控制；
> （2）掌握：目录检索过程，文件数据访问基本过程，FAT文件系统设计实现。

#### 文件管理概论

文件系统 = 文件管理程序 + 它所管理的全部文件 + 文件管理所需的数据结构
文件管理五大功能（用户角度 + 系统角度）：
1）文件存储空间管理（即外存管理），分配与回收；
2）文件目录管理；
3）实现逻辑文件到物理文件的转换和映射；
4）实现对文件的各种控制操作和存取操作；
5）实现文件信息的共享，以及文件保密和保护措施。

###### 文件类型

- 按文件性质与用途分类
  
  - 系统文件、用户文件、库文件

- 按文件中的数据形式分类
  
  - 源文件、目标文件、可执行文件

- 按存取控制属性分类
  
  - 只执行文件、只读文件、读写文件

- 按文件逻辑/物理结构分类
  
  - 有结构文件（记录式文件）
    
    - 顺序文件
    
    - 索引文件
    
    - 索引顺序文件
  
  - 无结构文件（字符流文件即流式文件）

![](C:\Users\17131\AppData\Roaming\marktext\images\2022-07-22-15-55-55-image.png)

###### 文件操作

- 创建/删除文件
  
  - 建立文件系统调用的一般格式：create（文件名，参数表）
  
  - 用户提供要创建的文件的文件名及若干参数，系统为这一新创建的文件分配一个文件控制块，根据用户提供的参数及系统控制需要填写文件控制块中的有关项。有的系统还返回给用户一个文件控制块描述符，以后用户使用该文件控制块描述符存取该文件。

- 读文件
  
  - 打开文件后，就可以读取文件中的信息。读文件系统调用的一般格式：read（文件名，记录键，内存位置）
  
  - 是把指定文件中给定键值的记录读入内存指定单元。

- 写文件
  
  - 写文件系统调用一般格式：write（文件名，记录键，内存位置）
  
  - 表示把内存中指定单元的数据作为指定键值的一个记录写入指定文件中，系统还将为其分配物理块，以把记录信息写在外存上。

- 截断文件

- 设置文件读/写位置

- 打开文件

- 关闭文件

- 文件属性设置与获取

- 目录操作、文件共享及其他操作

#### 文件的逻辑结构

###### 概述

###### 顺序文件逻辑结构及直接存取

###### 索引文件逻辑结构

###### 索引顺序文件逻辑结构

### 外存分配方式

##### 物理结构

        概念：文件在外存上的存储组织形式称作文件的物理结构

###### 文件物理结构外存分配概述

##### 连续分配

##### 链接分配

##### 索引分配

    引入多级索引分配方式 解决文件太大、索引块太多时用链接指针来链接索引块的方法低效

##### 直接文件和散列文件

> 2017年简答：怎样才能有效地利用外存空间和如何提高对文件的访问速度？阐明Unix System V文件系统采用的 混合索引方式是如何达到上述目的的。比较混合索引方式相对于连续分配、链接分配和索引分配方式的优势
> 
> 答：UNIX系统中采用混合索引分配方式，指将多种索引分配方式相结合而形成的分配方式。系统既采用了直接地址，又采用了一级索引分配方式，两级索引分配方式，三级索引分配方式。在UNIX System V的索引结点中，共设有13个地址项，即iaddr(0)-iaddr(12)。（1）用iaddr(0)-iaddr(9)存放直接地址。（2）地址项iaddr(10)提供一次间接地址。（3）用地址项iaddr(11)提供二次间接地址，地址项iaddr(12)作为三次间接地址。
> 
> 混合索引分配方式避免了连续分配的外部碎片以及文件长度受限问题，链接方式的不能直接高效存取以及FAT需较大空间的问题，索引分配的系统存储空间开销大、不适合小文件的问题。

### 文件存储管理

###### 文件存储空间管理目标

外存空间利用与文件访问速度

###### 空闲表法

###### 空闲链表法

###### 位示图法

（利用一个二进制位表示一个磁盘盘块使用情况，使磁盘上所有盘块都与一个二进制位相对应）

###### 成组链接法（重点）

（FAT文件分配表、连续分配、成组链接法计算盘块号问题）

### 文件目录结构及管理

##### 目录管理基本要求

引入：为了文件的有效管理与组织要求基于文件名便能快速、准确地找到指定文件

文件目录具有将文件名转换为该文件在外存的物理位置的功能

功能：

1. 实现“按名存取”

2. 提高目录检索速度及文件存取速度

3. 文件共享（外存保留一份文件副本）

4. 允许文件重名，以便于文件使用

##### 文件控制块

-   概念
  
  - 文件 文件控制块 文件目录项    
  
  - 文件目录 文件控制块有序集合 目录文件

- 信息内容
  
  - 基本信息（文件名、物理位置、结构类型）
  
  - 存取控制信息（各类用户存取权限）
  
  - 使用信息（修改日期及实践
    
    当前使用信息

FAT12文件系统标准

##### 索引结点

        概念：使文件描述信息单独形成一个称为索引结点的数据结构

###### 磁盘索引结点

###### 内存索引结点

> 磁盘索引结点和内存索引结点有什么区别
> 
> 磁盘索引结点放在磁盘上，与文件一一对应，包括文件的一些描述信息
> 
> 内存索引结点存放在内存，文件被打开时，将磁盘索引结点拷贝到内存的索引结点中，又增加了一些文件的使用信息

##### 目录结构

###### 单级目录结构

###### 两级目录结构

###### 树形目录结构

###### 无环图目录结构

##### 目录检索过程（掌握）

###### 实现文件按名存取的基本步骤

1. 系统根据用户提供的文件名，对文件目录进行查询，找出该文件的文件控制块或索引结点
2. 按照对应文件控制块或索引结点中所记录的文件物理地址（盘块号），计算出文件在磁盘上的物理地址
3. 启动磁盘驱动程序，将所存取的文件读入内存进行具体读写操作

###### 目录查询技术

线性检索法（顺序检索法）和散列方法

##### 典型存取操作逻辑流程（重点问题）

- 用户程序读盘请求的整个过程
  
  - 请求者进程从用户空间进入核心态
  
  - 设备无关性软件执行
  
  - 磁盘驱动进程调度运行
  
  - 通道控制磁盘设备完成相应数据的读取操作
  
  - CPU响应通道发来的中断请求和完成中断处理
  
  - 磁盘驱动进程再次调度运行
  
  - 请求者进程再次调度执行和返回用户空间
1. 请求者进程从用户空间进入核心态
   
   1. 用户空间执行函数read(fd,2700,100)，准备系统调用参数
   
   2. 通过系统调用进入核心态

2. 设备无关性软件执行
   
   1. 调用逻辑文件系统计算要读取的数据所在的逻辑盘块号 int[2700/512]=[5]
   
   2. 确定yourfile所在的设备、把逻辑盘块号转换为物理盘块号
   
   3. 申请分配输入缓冲区
   
   4. 把读盘操作的参数（文件名、所在的设备、物理
      块号、缓冲区地址）通知磁盘驱动进程
   
   5. 唤醒磁盘驱动进程
   
   6. 请求者进程阻塞

3. 磁盘驱动进程调度运行
   
   1. 检查确认输入缓冲区无所读取的数据
   
   2. 根据读操作的参数将一维物理块号转换为三维物理地址（柱面号、磁头号、扇区号）
   
   3. 自动组织和生成通道程序
   
   4. 启动通道与磁盘设备
   
   5. 磁盘驱动进程自行阻塞

4. 通道控制磁盘设备完成相应数据的读取操作
   
   1. 通道从内存提取并执行通道程序，控制磁盘设备完成数据读取操作
   
   2. 通道发出中断信号

5. CPU响应通道发来的中断请求
   
   1. 正在执行其它进程的CPU响应设备中断信号
   
   2. 通过外中断进入核心态
   
   3. 再次唤醒磁盘驱动程序
   
   4. 分析中断原因，进行磁盘中断处理
   
   5. 从中断返回

6. 磁盘驱动进程再次调度运行
   
   1. 设备驱动进程把输入缓冲区中的数据分离出来并传送到请求者进程的数据区，即从缓冲区内偏移地址
   
   2. 唤醒请求者进程，磁盘驱动程序自行阻塞

7. 请求者进程再次调度执行和返回用户空间
   
   1. 释放输入缓冲区
   
   2. 请求者进程返回用户态

### 文件共享与保护

##### 概念

指系统应允许多个用户（进程）共享同一份文件，从而在系统中只需保存该共享文件的一个副本即可

必要性：如果系统不能提供文件共享功能，就意味着凡是需要该文件的用户，都须各自备有此文件的副本，因此必然会造成存储空间的极大浪费

###### 早期技术

- 绕弯路法

- 连访法 

- 基于基本文件目录实现文件共享

##### 基于索引节点的文件共享方法（硬链接）

- 基于文件目录建立文件共享关系
  
  - 1：FCB在不同目录文件中的拷贝
    
    - 一旦文件发生改变，一致性难以保证
  
  - 2：符号目录与索引节点相结合
    
    - 指针悬空问题

优点：不需新文件；文件移动到新目录后仍能访问

缺点：只能链接到同一文件系统的文件；会在原来目录树中引入环路

##### 利用符号链实现文件共享（软链接）

优点：没有文件系统的限制，比较灵活

缺点：需要创建新的文件，浪费外存空间；文件移动后不能正常访问

> 2015简答：现代文件系统通常支持通过不同的路径访问同一文件，阐述实现此项功能的主要途径？各有什么优缺点？
> 
> 2018简答：操作系统中，典型的文件共享机制有哪些？它们是如何实现的，各有什么优缺点？（8分）

##### 文件系统安全保护

- 系统级安全管理
  
  - 注册与登陆（注册用户表）

- 用户级安全管理
  
  - 用户分类及访问权设定

- 目录级安全管理
  
  - 目录的读/写/执行许可权

- 文件级安全管理
  
  - 文件属性及有效访问权

##### 磁盘容错技术

- 基本概念
  
  - 设置冗余部件以提高系统可靠性

- 低级磁盘容错技术SFT-I
  
  - 双份目录与双份文件分配表
  
  - 热修复重定向、写后读校验

- 中级磁盘容错技术SFT-II
  
  - 磁盘镜像与磁盘双工 

### 文件系统性能改善策略及数据一致性控制

检查点及恢复算法改进

文件数据访问基本过程（掌握）

FAT文件系统设计实现（掌握） 

作业题：

**6.1 阐述文件管理的目标、功能及技术手段，并就文件系统层次结构模型进行讨论**

**6.2 分别就数据项、记录、关键字和文件的概念进行解释，并就文件的分类展开讨论**

**6.3 通常，文件系统应提供哪些基本文件操作类型？并就其功能实现分别进行简要说明。**

**6.4 什么是文件的逻辑结构？其基本设计要求是什么？并就主要的文件逻辑结构类型特别是顺序文件、索引文件、索引顺序文件等从组织结构、检索方法、检索速度和存储费用等方面展开简明扼要的说明和讨论。**

**6.5 什么是文件的物理结构？其基本设计要求是什么？并就主要的文件物理结构类型及外存分配方式展开简明扼要的说明和讨论。**

**6.6[必做] 假定盘块的大小为4KB，对于10GB的硬盘，其文件分配表需占用多少存储空间？当硬盘容量为40GB时，文件分配表又需占用多少存储空间？**

**6.7[必做] 假如盘块的大小为4KB，每个盘块号占4个字节，在两级索引分配时，允许的最大文件是多少**

**6.8 文件存储空间管理的基本目标是什么？关于空闲存储空间的管理通常可基于哪些数据结构及方法进行描述和管理？并逐一进行简要说明。**

**6.9[必做] 计算机系统利用位示图（详参作业手册）来管理空闲盘块，盘块大小为1KB，现要为某文件分配两个盘块，试说明盘块分配的具体过程。**

**6.10[必做] 某计算机系统磁盘容量为520MB，盘块大小为1KB。其中前4MB用于存放索引结点等，后10MB用作对换区，采用成组链接法管理外存空间，每组100个盘块。试画出外存尚未使用的成组链接图。**

成组链接法所管理外存空间为4MB~ (520MB-10MB-1B),即4MB~(510MB-1B)，共506MB。对应盘块号范围为4MB/1KB~[(510MB-1B)/1KB-1]，即4K~(510K-1)，也就是4096~522239。按每组100 盘 块 ， 即 4096~4195 ， 4196~4295 ，4296~4395 ， „ ， 522096~522195 ， 522196~522239。最末一组拥有44个盘块，但由于需填补0作为栈底，所以实际记作45

**6.11 文件目录管理的基本要求有哪些？从索引结点和目录结构等两方面阐述目录管理技术的演化发展，并就树形目录结构中文件的按名存取和目录检索技术举例展开详细说明。**

**6.12 阐述文件共享的概念及必要性，并从基本思想和优缺点评析等角度就绕弯路法、连访法以及基于基本目录、索引结点、符号链的文件共享方式展开讨论。**

**6.13 影响文件系统安全的主要因素有哪些？如何构建完备的文件系统安全管理体系？并着重就存取控制机制的实现及访问矩阵的优化、磁盘容错技术及所涉关键概念等展开讨论。**

**6.14 谈谈你对数据的一致性问题以及事务、检查点等概念与恢复算法和并发控制技术的认识与理解，并着重就几种典型的重复数据一致性问题及其解决方案进行讨论。**

**6.15 综合分析可通过哪些途径改善文件系统的性能？**

**6.16 内存管理和外存管理有哪些异同？试展开深入的分析和说明。**
